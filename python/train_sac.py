#!/usr/bin/env python3
"""
–û–±—É—á–µ–Ω–∏–µ SAC –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö BTC/USDT
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import time

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from environment.trading_env import TradingEnvironment
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.monitor import Monitor

def load_real_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    print("üìä –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ BTC/USDT...")
    
    data_file = "data/BTCUSDT_1h_2020-01-01_2024-12-31.csv"
    
    if not os.path.exists(data_file):
        print(f"‚ùå –§–∞–π–ª {data_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ download_data.py")
        return None
    
    df = pd.read_csv(data_file, index_col='timestamp', parse_dates=True)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π")
    
    return df

def create_vec_env(env):
    """–°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é —Å—Ä–µ–¥—É –¥–ª—è Stable-Baselines3"""
    def make_env():
        return Monitor(env)
    
    return DummyVecEnv([make_env])

def setup_callbacks(eval_env):
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–±—ç–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    callbacks = []
    
    # –ö–æ–ª–±—ç–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path="./models/best_model/",
        log_path="./logs/eval/",
        eval_freq=5000,  # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–µ 5000 —à–∞–≥–æ–≤
        deterministic=True,
        render=False
    )
    callbacks.append(eval_callback)
    
    # –ö–æ–ª–±—ç–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
    checkpoint_callback = CheckpointCallback(
        save_freq=10000,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–µ 10000 —à–∞–≥–æ–≤
        save_path="./models/checkpoints/",
        name_prefix="trading_model"
    )
    callbacks.append(checkpoint_callback)
    
    return callbacks

def train_ppo_model(env, total_timesteps=100000):
    """–û–±—É—á–∞–µ–º PPO –º–æ–¥–µ–ª—å"""
    print(f"\nüß† –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ PPO –º–æ–¥–µ–ª–∏ –Ω–∞ {total_timesteps} —à–∞–≥–∞—Ö...")
    
    # –°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é —Å—Ä–µ–¥—É
    vec_env = create_vec_env(env)
    
    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å
    model = PPO(
        "MlpPolicy",
        vec_env,
        verbose=1,
        learning_rate=3e-4,
        batch_size=256,
        n_steps=2048,
        gamma=0.99,
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.01
    )
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–±—ç–∫–∏
    callbacks = setup_callbacks(vec_env)
    
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    os.makedirs("./models/best_model/", exist_ok=True)
    os.makedirs("./models/checkpoints/", exist_ok=True)
    os.makedirs("./logs/eval/", exist_ok=True)

    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    start_time = time.time()
    
    model.learn(
        total_timesteps=total_timesteps,
        callback=callbacks
    )
    
    training_time = time.time() - start_time
    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {training_time:.2f} —Å–µ–∫—É–Ω–¥!")
    
    return model

def evaluate_model(model, env, n_episodes=5):
    """–û—Ü–µ–Ω–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print(f"\nüß™ –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ {n_episodes} —ç–ø–∏–∑–æ–¥–∞—Ö...")
    
    total_rewards = []
    total_pnls = []
    win_rates = []
    
    for episode in range(n_episodes):
        print(f"\n--- –≠–ø–∏–∑–æ–¥ {episode + 1} ---")
        
        obs, info = env.reset()
        episode_reward = 0
        done = False
        step = 0
        
        while not done and step < 500:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, truncated, info = env.step(action)
            episode_reward += reward
            step += 1
            
            if step % 100 == 0:
                print(f"   –®–∞–≥ {step}: –î–µ–π—Å—Ç–≤–∏–µ={action}, –ë–∞–ª–∞–Ω—Å={info['balance']:.2f}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —ç–ø–∏–∑–æ–¥–∞
        stats = env.get_statistics()
        total_rewards.append(episode_reward)
        total_pnls.append(stats.get('total_return', 0))
        win_rates.append(stats.get('win_rate', 0))
        
        print(f"   –≠–ø–∏–∑–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {step} —à–∞–≥–æ–≤")
        print(f"   –û–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {episode_reward:.6f}")
        print(f"   –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: {info['balance']:.2f}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫: {info['trades_count']}")
        print(f"   Win Rate: {stats.get('win_rate', 0):.2f}")
        print(f"   –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {stats.get('total_return', 0):.4f}")
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        'mean_reward': np.mean(total_rewards),
        'std_reward': np.std(total_rewards),
        'mean_return': np.mean(total_pnls),
        'std_return': np.std(total_pnls),
        'mean_win_rate': np.mean(win_rates),
        'std_win_rate': np.std(win_rates)
    }
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
    print(f"   –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {results['mean_reward']:.6f} ¬± {results['std_reward']:.6f}")
    print(f"   –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results['mean_return']:.6f} ¬± {results['std_return']:.6f}")
    print(f"   –°—Ä–µ–¥–Ω–∏–π Win Rate: {results['mean_win_rate']:.4f} ¬± {results['std_win_rate']:.4f}")
    
    return results

def save_model(model, filename=None):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å"""
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"trading_model_ppo_{timestamp}"
    
    model_path = f"./models/{filename}"
    model.save(model_path)
    
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")
    return model_path

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("ü§ñ –û–±—É—á–µ–Ω–∏–µ SAC –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö BTC/USDT")
    print("=" * 60)
    
    try:
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = load_real_data()
        if data is None:
            return
        
        # 2. –°–æ–∑–¥–∞—ë–º —Å—Ä–µ–¥—É
        print("\nüéÆ –°–æ–∑–¥–∞—ë–º —Ç–æ—Ä–≥–æ–≤—É—é —Å—Ä–µ–¥—É...")
        env = TradingEnvironment(
            data=data,
            window_size=64,
            commission_rate=0.0004,
            slippage_rate=0.0001,
            initial_balance=10000.0,
            max_position_size=0.1
        )
        
        print(f"‚úÖ –°—Ä–µ–¥–∞ —Å–æ–∑–¥–∞–Ω–∞:")
        print(f"   - –†–∞–∑–º–µ—Ä –Ω–∞–±–ª—é–¥–µ–Ω–∏—è: {env.observation_space.shape}")
        print(f"   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π: {env.action_space.n}")
        print(f"   - –ú–∞–∫—Å–∏–º—É–º —à–∞–≥–æ–≤: {env.max_steps}")
        
        # 3. –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model = train_ppo_model(env, total_timesteps=50000)  # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–∞–ª–æ–≥–æ
        
        # 4. –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        results = evaluate_model(model, env, n_episodes=3)
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        model_path = save_model(model)
        
        print("\n" + "=" * 60)
        print("üéâ –û–±—É—á–µ–Ω–∏–µ PPO –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: Win Rate = {results['mean_win_rate']:.2f}")
        
        print("\nüìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        print("2. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ ONNX –¥–ª—è Node.js")
        print("3. –°–æ–∑–¥–∞—Ç—å Node.js –±–æ—Ç–∞")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
